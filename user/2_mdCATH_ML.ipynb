{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDCATH DATASET IN MACHINE LEARNING FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides a practical example of training ML models using the mdCATH dataset in TorchMD-Net. Before you begin, please ensure that TorchMD-Net is correctly installed. You can find installation instructions and further details [here](https://torchmd-net.readthedocs.io/en/latest/installation.html). Note that the MDCATH dataloader is available starting from TorchMD-Net version 2.4.0 and later. The next cell will write and environment file, then it's possible to create the env using the following command:\n",
    "\n",
    "```bash\n",
    "mamba env create -f environment.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile environment.yaml\n",
    "name: torchmdnet_env\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - torchmdnet>=2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from torchmdnet.data import DataModule\n",
    "from torchmdnet.module import LNNP\n",
    "from torchmdnet.scripts.train import get_args\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments\n",
    "args = get_args() # default arguments by tmdnet\n",
    "args = vars(args) # convert to dictionary\n",
    "\n",
    "pargs = {\n",
    "    # DATA\n",
    "    'dataset': 'MDCATH',\n",
    "    'dataset_arg':{\n",
    "      'numAtoms': None,\n",
    "      'numResidues': None,\n",
    "      'pdb_list': ['1balA00', '1ce3A00', '1e8rA00'],\n",
    "      'temperatures': ['348'],\n",
    "      'skip_frames': 2,\n",
    "      'solid_ss': None,\n",
    "      },\n",
    "    'dataset_root': 'data',\n",
    "    # MODEL\n",
    "    'model': 'tensornet',\n",
    "    'embedding_dimension': 32,\n",
    "    'num_layers': 0,\n",
    "    'num_rbf': 8,\n",
    "    'rbf_type': 'expnorm',\n",
    "    'activation': 'silu',\n",
    "    'cutoff_lower': 0.0,\n",
    "    'cutoff_upper': 5.0,\n",
    "    'max_z': 20,\n",
    "    'num_epochs': 10,\n",
    "    'max_num_neighbors': 48,\n",
    "    'derivative': True, \n",
    "    # TRAIN\n",
    "    'batch_size': 3,\n",
    "    'train_size': 200, \n",
    "    'val_size': 50,\n",
    "    'test_size': 100,\n",
    "    'lr': 1e-3,\n",
    "    'lr_metric': 'val',\n",
    "    'log_dir': 'logs/',\n",
    "    'check_errors': True,\n",
    "    'static_shapes': False,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "# Update the default arguments with the new ones\n",
    "args.update(pargs)\n",
    "os.makedirs(args['log_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing mdcath source: 100%|██████████| 3/3 [00:00<00:00, 135.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 200, val 50, test 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/torchmdnet/utils.py:221: UserWarning: 2970 samples were excluded from the dataset\n",
      "  rank_zero_warn(f\"{dset_len - total} samples were excluded from the dataset\")\n"
     ]
    }
   ],
   "source": [
    "# Here MDCATH torch_geometric dataset class is used \n",
    "# If the h5 files are not present in the 'dataset_root' then they will be downloaded from HF\n",
    "# The downlaoad process can take some time\n",
    "\n",
    "data = DataModule(args)\n",
    "data.prepare_data()\n",
    "data.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightning wrapper for the Neural Network Potentials in TorchMD-Net\n",
    "lnnp = LNNP(args, \n",
    "    prior_model=None, \n",
    "    mean=data.mean, \n",
    "    std=data.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks, used to save model ckpts\n",
    "val_loss_name = 'val_total_mse_loss'\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=args['log_dir'], \n",
    "                                      monitor=val_loss_name, \n",
    "                                      every_n_epochs=2, \n",
    "                                      filename=f\"epoch={{epoch}}-val_loss={{{val_loss_name}:.4f}}\",\n",
    "                                      save_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger for the training process, it will save the training logs in a csv file\n",
    "csv_logger = CSVLogger(args['log_dir'], name=\"\", version=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "cuda device count: 4\n",
      "CUDA_VISIBLE_DEVICES ID: 0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "print(f'cuda available: {torch.cuda.is_available()}')\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "print(f'CUDA_VISIBLE_DEVICES ID: {os.environ[\"CUDA_VISIBLE_DEVICES\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /shared/antoniom/mambaforge/envs/gemini2/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/lightning/fabric/loggers/csv_logs.py:196: Experiment logs directory logs/ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:630: Checkpoint directory logs/ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | TorchMD_Net | 18.9 K\n",
      "--------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 200, val 50, test 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0609e4441994943b59f4c2e3d0ec6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0abf911d684d04b5990fdf902ff790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: torchmdnet_extensions::get_neighbor_pairs_bkwd: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580525958/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ffa10e23274130b9ec2d281ddb6213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2833e571189442b9a07a3dd631c93f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccd2f54bd104ee1a71b48ab682c6847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffeb8192356d414ab8888803c3dc3a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898ec3ec53eb42fc9e3af4b7eda618f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802cfef058744ab98cf107700614770f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d3654817a44e35a0c307f6ff6a2f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101b2c829f1341209e4213cfc5b628bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb25d6b236f42e3aa84b2c01678a09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a02b9dc38f341acb6461eae028ded9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer = pl.Trainer(strategy=\"auto\",\n",
    "                     devices=1,\n",
    "                     max_epochs=args['num_epochs'], \n",
    "                     precision=args['precision'],\n",
    "                     default_root_dir = args['log_dir'],\n",
    "                     logger=csv_logger,\n",
    "                     callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=1)])\n",
    "\n",
    "trainer.fit(lnnp, data, ckpt_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /shared/antoniom/mambaforge/envs/gemini2/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/shared/antoniom/mambaforge/envs/gemini2/lib/python3.10/site-packages/torchmdnet/utils.py:221: UserWarning: 2970 samples were excluded from the dataset\n",
      "  rank_zero_warn(f\"{dset_len - total} samples were excluded from the dataset\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 200, val 50, test 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a47e86d37ce404295e55a7a54d5163d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_neg_dy_l1_loss    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.440413475036621     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_total_l1_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.440413475036621     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_y_l1_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_neg_dy_l1_loss   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.440413475036621    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_total_l1_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.440413475036621    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_y_l1_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_total_l1_loss': 4.440413475036621,\n",
       "  'test_y_l1_loss': 0.0,\n",
       "  'test_neg_dy_l1_loss': 4.440413475036621}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "model = LNNP.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "trainer = pl.Trainer(inference_mode=False)\n",
    "trainer.test(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
